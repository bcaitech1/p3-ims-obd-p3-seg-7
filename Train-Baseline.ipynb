{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:58.944902Z",
     "start_time": "2021-04-22T11:06:56.623974Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import vgg16\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.171980Z",
     "start_time": "2021-04-22T11:06:59.167952Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 2\n",
    "learning_rate = 0.0001\n",
    "model_name = 'test_fcn8s_best_model'\n",
    "\n",
    "val_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:06:59.446510Z",
     "start_time": "2021-04-22T11:06:59.443508Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이름 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dir = 'saved'\n",
    "model_path = os.path.join(saved_dir, f'{model_name}.pt')\n",
    "\n",
    "dataset_path = 'data'\n",
    "train_path = os.path.join(dataset_path, 'train.json')\n",
    "val_path = os.path.join(dataset_path, 'val.json')\n",
    "test_path = os.path.join(dataset_path, 'test.json')\n",
    "\n",
    "category_names = ['Backgroud', 'UNKNOWN', 'General trash', 'Paper', 'Paper pack', \\\n",
    "                  'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', \\\n",
    "                  'Battery', 'Clothing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 (transfrorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Normalize((0.4185, 0.4398, 0.461), (0.2466, 0.2345, 0.2382)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize((0.4185, 0.4398, 0.461), (0.2466, 0.2345, 0.2382)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize((0.4185, 0.4398, 0.461), (0.2466, 0.2345, 0.2382)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:29.119807Z",
     "start_time": "2021-04-22T11:15:29.109808Z"
    }
   },
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "    def __init__(self, num_classes=12, init_weights=True):\n",
    "        super(MODEL, self).__init__()\n",
    "        self.pretrained_model = vgg16(pretrained = True)\n",
    "        features, classifiers = list(self.pretrained_model.features.children()), list(self.pretrained_model.classifier.children())\n",
    "\n",
    "        self.features_map1 = nn.Sequential(*features[0:17])\n",
    "        self.features_map2 = nn.Sequential(*features[17:24])\n",
    "        self.features_map3 = nn.Sequential(*features[24:31])\n",
    "        \n",
    "        # Score pool3\n",
    "        self.score_pool3_fr = nn.Conv2d(256, num_classes, 1)\n",
    "        \n",
    "        # Score pool4        \n",
    "        self.score_pool4_fr = nn.Conv2d(512, num_classes, 1)        \n",
    "        \n",
    "        # fc6 ~ fc7\n",
    "        self.conv = nn.Sequential(nn.Conv2d(512, 4096, kernel_size = 1),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Conv2d(4096, 4096, kernel_size = 1),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Dropout()\n",
    "                                  )\n",
    "        \n",
    "        # Score\n",
    "        self.score_fr = nn.Conv2d(4096, num_classes, kernel_size = 1)\n",
    "        \n",
    "        # UpScore2 using deconv\n",
    "        self.upscore2 = nn.ConvTranspose2d(num_classes,\n",
    "                                           num_classes,\n",
    "                                           kernel_size=4,\n",
    "                                           stride=2,\n",
    "                                           padding=1)\n",
    "        \n",
    "        # UpScore2_pool4 using deconv\n",
    "        self.upscore2_pool4 = nn.ConvTranspose2d(num_classes, \n",
    "                                                 num_classes, \n",
    "                                                 kernel_size=4,\n",
    "                                                 stride=2,\n",
    "                                                 padding=1)\n",
    "        \n",
    "        # UpScore8 using deconv\n",
    "        self.upscore8 = nn.ConvTranspose2d(num_classes, \n",
    "                                           num_classes,\n",
    "                                           kernel_size=16,\n",
    "                                           stride=8,\n",
    "                                           padding=4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pool3 = h = self.features_map1(x)\n",
    "        pool4 = h = self.features_map2(h)\n",
    "        h = self.features_map3(h)\n",
    "        \n",
    "        h = self.conv(h)\n",
    "        h = self.score_fr(h)\n",
    "       \n",
    "        score_pool3c = self.score_pool3_fr(pool3)    \n",
    "        score_pool4c = self.score_pool4_fr(pool4)\n",
    "        \n",
    "        # Up Score I\n",
    "        upscore2 = self.upscore2(h)\n",
    "        \n",
    "        # Sum I\n",
    "        h = upscore2 + score_pool4c\n",
    "        \n",
    "        # Up Score II\n",
    "        upscore2_pool4c = self.upscore2_pool4(h)\n",
    "        \n",
    "        # Sum II\n",
    "        h = upscore2_pool4c + score_pool3c\n",
    "        \n",
    "        # Up Score III\n",
    "        upscore8 = self.upscore8(h)\n",
    "        \n",
    "        return upscore8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:34.624277Z",
     "start_time": "2021-04-22T11:15:30.068347Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(num_classes=12).to(device)\n",
    "x = torch.randn([1, 3, 512, 512]).to(device)\n",
    "out = model(x)\n",
    "print(\"input shape : \", x.shape)\n",
    "print(\"output shape : \", out.size())\n",
    "\n",
    "del x, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:04.439837Z",
     "start_time": "2021-04-22T11:07:04.425804Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_classname(classID, cats):\n",
    "    for cat in cats:\n",
    "        if cat['id'] == classID:\n",
    "            return cat['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:07:09.179806Z",
     "start_time": "2021-04-22T11:07:04.440804Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "#                                            num_workers=2,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "#                                          num_workers=2,\n",
    "                                         collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "#                                           num_workers=2,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation, test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.201874Z",
     "start_time": "2021-04-22T11:15:38.187884Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    best_loss = 10\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        with tqdm(data_loader, unit=\"batch\") as loader:\n",
    "            loader.set_description(f\"Epoch {epoch}\")\n",
    "            loss_sum, n_batch = 0., 0.\n",
    "            \n",
    "            for images, masks, _ in loader:\n",
    "                images = torch.stack(images)       # (batch, channel, height, width)\n",
    "                masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "                # gpu 연산을 위해 device 할당\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                # inference\n",
    "                outputs = model(images)\n",
    "\n",
    "                # loss 계산 (cross entropy loss)\n",
    "                loss = criterion(outputs, masks)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # step 주기에 따른 loss 출력\n",
    "                n_batch += 1\n",
    "                loss_sum += loss.item()\n",
    "                loader.set_postfix(loss=loss_sum / n_batch)\n",
    "        \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss, avrg_mIoU = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                best_loss = avrg_loss\n",
    "                best_epoch = epoch\n",
    "                save_model(model)\n",
    "        \n",
    "            print(f'Best performance at epoch: {best_epoch}, loss: {avrg_loss:.4f}, mIoU: {avrg_mIoU:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:38.901226Z",
     "start_time": "2021-04-22T11:15:38.888195Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        mIoU_list = []\n",
    "        \n",
    "        with tqdm(data_loader, unit=\"batch\") as loader:\n",
    "            loader.set_description(f\"Valid {epoch}\")\n",
    "            loss_sum, n_batch = 0., 0.\n",
    "            \n",
    "            for images, masks, _ in loader:\n",
    "                images = torch.stack(images)       # (batch, channel, height, width)\n",
    "                masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "                images, masks = images.to(device), masks.to(device)            \n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                total_loss += loss.item()\n",
    "                cnt += 1\n",
    "\n",
    "                outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "                mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n",
    "                mIoU_list.append(mIoU)\n",
    "                \n",
    "                loader.set_postfix(loss=total_loss / cnt, mIoU=np.mean(mIoU_list))\n",
    "            \n",
    "    return total_loss / cnt, np.mean(mIoU_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 및 Loss function, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T11:15:43.106368Z",
     "start_time": "2021-04-22T11:15:43.096368Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, output_path=model_path):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    torch.save(model.state_dict(), output_path)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-22T11:15:43.700Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 Best Model 불러오기 (학습된 이후) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:21.050200Z",
     "start_time": "2021-04-16T19:44:20.802200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:24.939227Z",
     "start_time": "2021-04-16T19:44:24.518228Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째 batch의 추론 결과 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos\n",
    "    temp_images = imgs\n",
    "    \n",
    "    model.eval()\n",
    "    # inference\n",
    "    outs = model(torch.stack(temp_images).to(device))\n",
    "    oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    break\n",
    "\n",
    "for i in range(batch_size):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n",
    "\n",
    "    print('Shape of Original Image :', list(temp_images[i].shape))\n",
    "    print('Shape of Predicted : ', list(oms[i].shape))\n",
    "    print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(oms[i]))])\n",
    "\n",
    "    # Original image\n",
    "    ax1.imshow(temp_images[i].permute([1,2,0]))\n",
    "    ax1.grid(False)\n",
    "    ax1.set_title(\"Original image : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "    # Predicted\n",
    "    ax2.imshow(oms[i])\n",
    "    ax2.grid(False)\n",
    "    ax2.set_title(\"Predicted : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:44:27.469285Z",
     "start_time": "2021-04-16T19:44:27.456021Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    print('Start prediction.')\n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(temp_images), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T19:45:42.235310Z",
     "start_time": "2021-04-16T19:44:30.499016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(f\"./submission/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
