{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "knowing-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-alabama",
   "metadata": {},
   "source": [
    "## Lesson 6 - Pretrained Model\n",
    " - 이번 실습 자료에서는 강의시간에 다루었던 torchvision 을 사용하여 pretrained 모델을 사용하는 방법에 대해 실습하겠습니다.\n",
    " - torchvision 의 pretrained model 리스트는 다음과 같습니다\n",
    " \n",
    " [List of torchvision models](https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py#L1-L14)\n",
    "```\n",
    "from .alexnet import *\n",
    "from .resnet import *\n",
    "from .vgg import *\n",
    "from .squeezenet import *\n",
    "from .inception import *\n",
    "from .densenet import *\n",
    "from .googlenet import *\n",
    "from .mobilenet import *\n",
    "from .mnasnet import *\n",
    "from .shufflenetv2 import *\n",
    "from . import segmentation\n",
    "from . import detection\n",
    "from . import video\n",
    "from . import quantization\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-quality",
   "metadata": {},
   "source": [
    "#### 가장 기본이라고 할 수 있는 Alextnet 모델 아키텍쳐를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guilty-pathology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import alexnet\n",
    "model = alexnet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-malaysia",
   "metadata": {},
   "source": [
    "#### Alexnet 의 pretrained 버전 또한 쉽게 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reasonable-stuff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = alexnet(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-nepal",
   "metadata": {},
   "source": [
    "#### torchvision 에서 해당 모델을 어떤 식으로 구현하였는지 직접 확인해보면 매우 도움이 많으 됩니다.\n",
    "Example:\n",
    "[source code](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py#L15-L50)\n",
    "```\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-management",
   "metadata": {},
   "source": [
    "#### 다른 모델들( e.g. vgg19, resnet18) 도 같은 방법으로 손 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agreed-button",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import vgg19_bn\n",
    "model = vgg19_bn(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-rabbit",
   "metadata": {},
   "source": [
    "#### Pretrained 모델을 내 태스크에 맞게 어떻게 사용할 수 있나요?\n",
    " - Trochvision 모델들은 보통 feature-extraction 파트, task-specific 파트로 크게 두 가지로 구성되어 있습니다.\n",
    " - Task specific 파트는 모델의 태스크(이미지 분류, 객체 인식 등) 에 따라 모두 다릅니다.\n",
    " - 심지어 같은 이미지 분류 안에서도, 어떤 데이터셋으로 pretrain 하였느냐에 따라 다를 수 있습니다.\n",
    " - 따라서, 우리도 우리 테스크에 맞게 task specific 파트는 새로 정의하여 사용하여야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-logistics",
   "metadata": {},
   "source": [
    " - 주로 이미지넷 데이터셋을 사용하여 pretrain 을 하기에 output_dim=1000 인 경우가 많습니다.\n",
    " - 따라서 우리 태스크의 클래스 갯수(18)에 맞게 재정의하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suburban-pattern",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 18\n",
    "model = vgg19_bn(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(512 * 7 * 7, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, num_classes),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-joshua",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ancient-poland",
   "metadata": {},
   "source": [
    "#### Weight Freeze\n",
    " - Weight freeze 란 해당 모듈의 graident 는 역전파 하지 않아 학습을 하지 않는다는 의미입니다.\n",
    " - 예를 들어, 우리가 하려는 태스크가 pretrain 한 태스크와 매우 유사하다면, feature 파트는 freeze 하여 학습하지 않고 새로 정의한 task specific 파트만 학습하는 것이 좋은 방법일 수 있습니다.\n",
    " - weight freeze 는 `requires_grad` 를 사용하여 쉽게 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "southern-liberal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param features.0.weight    required gradient? -> False\n",
      "param features.0.bias      required gradient? -> False\n",
      "param features.1.weight    required gradient? -> False\n",
      "param features.1.bias      required gradient? -> False\n",
      "param features.3.weight    required gradient? -> False\n",
      "param features.3.bias      required gradient? -> False\n",
      "param features.4.weight    required gradient? -> False\n",
      "param features.4.bias      required gradient? -> False\n",
      "param features.7.weight    required gradient? -> False\n",
      "param features.7.bias      required gradient? -> False\n",
      "param features.8.weight    required gradient? -> False\n",
      "param features.8.bias      required gradient? -> False\n",
      "param features.10.weight   required gradient? -> False\n",
      "param features.10.bias     required gradient? -> False\n",
      "param features.11.weight   required gradient? -> False\n",
      "param features.11.bias     required gradient? -> False\n",
      "param features.14.weight   required gradient? -> False\n",
      "param features.14.bias     required gradient? -> False\n",
      "param features.15.weight   required gradient? -> False\n",
      "param features.15.bias     required gradient? -> False\n",
      "param features.17.weight   required gradient? -> False\n",
      "param features.17.bias     required gradient? -> False\n",
      "param features.18.weight   required gradient? -> False\n",
      "param features.18.bias     required gradient? -> False\n",
      "param features.20.weight   required gradient? -> False\n",
      "param features.20.bias     required gradient? -> False\n",
      "param features.21.weight   required gradient? -> False\n",
      "param features.21.bias     required gradient? -> False\n",
      "param features.23.weight   required gradient? -> False\n",
      "param features.23.bias     required gradient? -> False\n",
      "param features.24.weight   required gradient? -> False\n",
      "param features.24.bias     required gradient? -> False\n",
      "param features.27.weight   required gradient? -> False\n",
      "param features.27.bias     required gradient? -> False\n",
      "param features.28.weight   required gradient? -> False\n",
      "param features.28.bias     required gradient? -> False\n",
      "param features.30.weight   required gradient? -> False\n",
      "param features.30.bias     required gradient? -> False\n",
      "param features.31.weight   required gradient? -> False\n",
      "param features.31.bias     required gradient? -> False\n",
      "param features.33.weight   required gradient? -> False\n",
      "param features.33.bias     required gradient? -> False\n",
      "param features.34.weight   required gradient? -> False\n",
      "param features.34.bias     required gradient? -> False\n",
      "param features.36.weight   required gradient? -> False\n",
      "param features.36.bias     required gradient? -> False\n",
      "param features.37.weight   required gradient? -> False\n",
      "param features.37.bias     required gradient? -> False\n",
      "param features.40.weight   required gradient? -> False\n",
      "param features.40.bias     required gradient? -> False\n",
      "param features.41.weight   required gradient? -> False\n",
      "param features.41.bias     required gradient? -> False\n",
      "param features.43.weight   required gradient? -> False\n",
      "param features.43.bias     required gradient? -> False\n",
      "param features.44.weight   required gradient? -> False\n",
      "param features.44.bias     required gradient? -> False\n",
      "param features.46.weight   required gradient? -> False\n",
      "param features.46.bias     required gradient? -> False\n",
      "param features.47.weight   required gradient? -> False\n",
      "param features.47.bias     required gradient? -> False\n",
      "param features.49.weight   required gradient? -> False\n",
      "param features.49.bias     required gradient? -> False\n",
      "param features.50.weight   required gradient? -> False\n",
      "param features.50.bias     required gradient? -> False\n",
      "param classifier.0.weight  required gradient? -> True\n",
      "param classifier.0.bias    required gradient? -> True\n",
      "param classifier.3.weight  required gradient? -> True\n",
      "param classifier.3.bias    required gradient? -> True\n",
      "param classifier.6.weight  required gradient? -> True\n",
      "param classifier.6.bias    required gradient? -> True\n"
     ]
    }
   ],
   "source": [
    "# Freeze only feauture parts\n",
    "model.features.requires_grad_(False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:20} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-sending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naked-referral",
   "metadata": {},
   "source": [
    "#### Weight initialization \n",
    " - weight 초기화는 종종 모델의 성능에 critical 한 영향을 줍니다.\n",
    " - 하지만 만약 pretrained 모델을 사용한다면 pretrained 부분은 초기화를 하지 말고, 재정의한 task specific 파트만 초기화하여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extended-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Initialize all weights using xavier uniform. \n",
    "    For more weight initialization methods, check https://pytorch.org/docs/stable/nn.init.html\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-empire",
   "metadata": {},
   "source": [
    "#### pretrained 모델을 가져와 가장 앞단 layer 의 weight 분포를 봐봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stretch-filling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 0.00e+00, 1.00e+01, 3.50e+01, 1.58e+02, 1.47e+03,\n",
       "        4.00e+01, 1.30e+01, 0.00e+00, 1.00e+00]),\n",
       " array([-1.644177  , -1.3200787 , -0.99598044, -0.67188215, -0.3477839 ,\n",
       "        -0.02368563,  0.30041263,  0.6245109 ,  0.9486092 ,  1.2727075 ,\n",
       "         1.5968057 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Before initialize weights\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))  # weight distribution for first conv weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-reunion",
   "metadata": {},
   "source": [
    "#### weight 초기화 후 분포를 봐 봅시다\n",
    " - `xavier_uniform` 으로 초기화하여 웨이트들이 uniform 한 분포를 가지게 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "environmental-briefing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([180., 165., 168., 165., 167., 172., 167., 190., 189., 165.]),\n",
       " array([-0.09949287, -0.07956971, -0.05964655, -0.03972339, -0.01980022,\n",
       "         0.00012294,  0.0200461 ,  0.03996926,  0.05989242,  0.07981558,\n",
       "         0.09973875], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Initalize all weights\n",
    "initialize_weights(model.features)\n",
    "\n",
    "# After initialize weights\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-income",
   "metadata": {},
   "source": [
    "#### task specific 한 부분만 초기화하엿습니다\n",
    " - feature extraction 파트는 초기화가 되지 않은 것은 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hydraulic-attraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 0.00e+00, 1.00e+01, 3.50e+01, 1.58e+02, 1.47e+03,\n",
       "        4.00e+01, 1.30e+01, 0.00e+00, 1.00e+00]),\n",
       " array([-1.644177  , -1.3200787 , -0.99598044, -0.67188215, -0.3477839 ,\n",
       "        -0.02368563,  0.30041263,  0.6245109 ,  0.9486092 ,  1.2727075 ,\n",
       "         1.5968057 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAR1UlEQVR4nO3dfYzc113v8ffnxiSlhVs78ZIG28UpWIWAQI1WaaAIVTWkSYrqINoqFSJuMTIVKU9FKi5IRCpCtPde3UAEBJnG1JGqtCU8xEBKMEmrCgmHbErz3JJtSGtbTrw0qaFUtAS+/DHHMHV2vQ+zO2P3vF/SaM7vnDPz+85o9JnfnvnNbKoKSVIf/tekC5AkjY+hL0kdMfQlqSOGviR1xNCXpI6sm3QBp7Nx48baunXrpMuQpLPK/fff/09VNTXf2Bkd+lu3bmVmZmbSZUjSWSXJZxcac3lHkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6ckZ/I1c6k23d8xcT2e+T73ndRParrw0e6UtSRwx9SeqIoS9JHTH0Jakjhr4kdWTR0E+yL8nxJA/PM/aLSSrJxradJDclmU3yYJJLh+buTPJ4u+xc3YchSVqKpRzpvx+48tTOJFuAK4DPDXVfBWxrl93AzW3u+cANwCuBy4AbkmwYpXBJ0vItGvpV9XHgmXmGbgTeCdRQ3w7g1ho4BKxPchHwWuBgVT1TVc8CB5nnjUSStLZWtKafZAdwtKoeOGVoE3B4aPtI61uoX5I0Rsv+Rm6SFwK/zGBpZ9Ul2c1gaYiXvvSla7ELSerWSo70vxW4GHggyZPAZuATSV4CHAW2DM3d3PoW6n+eqtpbVdNVNT01Ne8/c5ckrdCyQ7+qHqqqb6qqrVW1lcFSzaVV9RRwALiuncVzOXCiqo4BdwFXJNnQPsC9ovVJksZoKads3gb8LfDyJEeS7DrN9DuBJ4BZ4PeBnwaoqmeAXwPua5d3tz5J0hgtuqZfVW9eZHzrULuA6xeYtw/Yt8z6JEmryG/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4uGfpJ9SY4neXio7/8m+VSSB5P8SZL1Q2PvSjKb5NNJXjvUf2Xrm02yZ9UfiSRpUUs50n8/cOUpfQeB76qq7wb+AXgXQJJLgGuB72y3+d0k5yQ5B/gd4CrgEuDNba4kaYwWDf2q+jjwzCl9f1VVz7XNQ8Dm1t4BfLCqvlxV/wjMApe1y2xVPVFVXwE+2OZKksZoNdb0fwL4SGtvAg4PjR1pfQv1P0+S3UlmkszMzc2tQnmSpJNGCv0kvwI8B3xgdcqBqtpbVdNVNT01NbVadytJAtat9IZJ3gL8MLC9qqp1HwW2DE3b3Po4Tb8kaUxWdKSf5ErgncDrq+pLQ0MHgGuTnJfkYmAb8HfAfcC2JBcnOZfBh70HRitdkrRcix7pJ7kNeDWwMckR4AYGZ+ucBxxMAnCoqt5WVY8k+TDwKINln+ur6j/a/bwduAs4B9hXVY+sweORJJ3GoqFfVW+ep/uW08z/deDX5+m/E7hzWdVJklaV38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrJo6CfZl+R4koeH+s5PcjDJ4+16Q+tPkpuSzCZ5MMmlQ7fZ2eY/nmTn2jwcSdLpLOVI//3Alaf07QHurqptwN1tG+AqYFu77AZuhsGbBHAD8ErgMuCGk28UkqTxWTT0q+rjwDOndO8A9rf2fuCaof5ba+AQsD7JRcBrgYNV9UxVPQsc5PlvJJKkNbbSNf0Lq+pYaz8FXNjam4DDQ/OOtL6F+p8nye4kM0lm5ubmVlieJGk+I3+QW1UF1CrUcvL+9lbVdFVNT01NrdbdSpJYeeg/3ZZtaNfHW/9RYMvQvM2tb6F+SdIYrTT0DwAnz8DZCdwx1H9dO4vncuBEWwa6C7giyYb2Ae4VrU+SNEbrFpuQ5Dbg1cDGJEcYnIXzHuDDSXYBnwXe1KbfCVwNzAJfAt4KUFXPJPk14L42791VdeqHw5KkNbZo6FfVmxcY2j7P3AKuX+B+9gH7llWdJGlV+Y1cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMjhX6SX0jySJKHk9yW5AVJLk5yb5LZJB9Kcm6be17bnm3jW1flEUiSlmzFoZ9kE/CzwHRVfRdwDnAt8F7gxqr6NuBZYFe7yS7g2dZ/Y5snSRqjUZd31gFfn2Qd8ELgGPAa4PY2vh+4prV3tG3a+PYkGXH/kqRlWHHoV9VR4P8Bn2MQ9ieA+4EvVNVzbdoRYFNrbwIOt9s+1+ZfcOr9JtmdZCbJzNzc3ErLkyTNY5TlnQ0Mjt4vBr4ZeBFw5agFVdXeqpququmpqalR706SNGSU5Z0fBP6xquaq6t+BPwZeBaxvyz0Am4GjrX0U2ALQxl8MfH6E/UuSlmmU0P8ccHmSF7a1+e3Ao8BHgTe0OTuBO1r7QNumjd9TVTXC/iVJyzTKmv69DD6Q/QTwULuvvcAvAe9IMstgzf6WdpNbgAta/zuAPSPULUlagXWLT1lYVd0A3HBK9xPAZfPM/TfgjaPsT5I0Gr+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkpNBPsj7J7Uk+leSxJN+b5PwkB5M83q43tLlJclOS2SQPJrl0dR6CJGmpRj3S/y3gL6vq24HvAR4D9gB3V9U24O62DXAVsK1ddgM3j7hvSdIyrTj0k7wY+AHgFoCq+kpVfQHYAexv0/YD17T2DuDWGjgErE9y0Ur3L0lavlGO9C8G5oA/SPL3Sd6X5EXAhVV1rM15CriwtTcBh4duf6T1fZUku5PMJJmZm5sboTxJ0qlGCf11wKXAzVX1CuBf+Z+lHACqqoBazp1W1d6qmq6q6ampqRHKkySdapTQPwIcqap72/btDN4Enj65bNOuj7fxo8CWodtvbn2SpDFZcehX1VPA4SQvb13bgUeBA8DO1rcTuKO1DwDXtbN4LgdODC0DSZLGYN2It/8Z4ANJzgWeAN7K4I3kw0l2AZ8F3tTm3glcDcwCX2pzJUljNFLoV9Ungel5hrbPM7eA60fZnyRpNH4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIyKGf5Jwkf5/kz9v2xUnuTTKb5EPtn6aT5Ly2PdvGt466b0nS8qzGkf7PAY8Nbb8XuLGqvg14FtjV+ncBz7b+G9s8SdIYjRT6STYDrwPe17YDvAa4vU3ZD1zT2jvaNm18e5svSRqTUY/0fxN4J/CfbfsC4AtV9VzbPgJsau1NwGGANn6izf8qSXYnmUkyMzc3N2J5kqRhKw79JD8MHK+q+1exHqpqb1VNV9X01NTUat61JHVv3Qi3fRXw+iRXAy8A/jfwW8D6JOva0fxm4GibfxTYAhxJsg54MfD5EfYvSVqmFR/pV9W7qmpzVW0FrgXuqaofAz4KvKFN2wnc0doH2jZt/J6qqpXuX5K0fGtxnv4vAe9IMstgzf6W1n8LcEHrfwewZw32LUk6jVGWd/5bVX0M+FhrPwFcNs+cfwPeuBr7kyStjN/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjqy4tBPsiXJR5M8muSRJD/X+s9PcjDJ4+16Q+tPkpuSzCZ5MMmlq/UgJElLM8qR/nPAL1bVJcDlwPVJLgH2AHdX1Tbg7rYNcBWwrV12AzePsG9J0gqsOPSr6lhVfaK1/wV4DNgE7AD2t2n7gWtaewdwaw0cAtYnuWil+5ckLd+qrOkn2Qq8ArgXuLCqjrWhp4ALW3sTcHjoZkdanyRpTEYO/STfAPwR8PNV9c/DY1VVQC3z/nYnmUkyMzc3N2p5kqQhI4V+kq9jEPgfqKo/bt1Pn1y2adfHW/9RYMvQzTe3vq9SVXurarqqpqempkYpT5J0ilHO3glwC/BYVf3/oaEDwM7W3gncMdR/XTuL53LgxNAykCRpDNaNcNtXAT8OPJTkk63vl4H3AB9Osgv4LPCmNnYncDUwC3wJeOsI+5YkrcCKQ7+q/gbIAsPb55lfwPUr3Z8kaXR+I1eSOjLK8o40cVv3/MWkS5DOKh7pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BF/T186y0zyfwg8+Z7XTWzfWh2GvlaF/8xEOju4vCNJHRl76Ce5Msmnk8wm2TPu/UtSz8a6vJPkHOB3gB8CjgD3JTlQVY+Os46vZS6zaC1N6vXlZwmrZ9xH+pcBs1X1RFV9BfggsGPMNUhSt8b9Qe4m4PDQ9hHglcMTkuwGdrfNLyb59JhqO2kj8E9j3udqsfbJsPY1lvfO231W1L6Ata79WxYaOOPO3qmqvcDeSe0/yUxVTU9q/6Ow9smw9smw9pUZ9/LOUWDL0Pbm1idJGoNxh/59wLYkFyc5F7gWODDmGiSpW2Nd3qmq55K8HbgLOAfYV1WPjLOGJZjY0tIqsPbJsPbJsPYVSFVNat+SpDHzG7mS1BFDX5I60n3oJ3ljkkeS/GeSBU+hSvJkkoeSfDLJzDhrXMgyaj/jfvoiyflJDiZ5vF1vWGDef7Tn/JNJJvqh/2LPY5Lzknyojd+bZOsEypzXEmp/S5K5oef6JydR56mS7EtyPMnDC4wnyU3tcT2Y5NJx17iQJdT+6iQnhp7zXx1LYVXV9QX4DuDlwMeA6dPMexLYOOl6l1s7gw/MPwO8DDgXeAC45Ayo/f8Ae1p7D/DeBeZ9cdK1LvV5BH4a+L3Wvhb40KTrXkbtbwF+e9K1zlP7DwCXAg8vMH418BEgwOXAvZOueRm1vxr483HX1f2RflU9VlXj/tbvqlhi7WfqT1/sAPa39n7gmsmVsiRLeR6HH9PtwPYkGWONCzlTXwOLqqqPA8+cZsoO4NYaOASsT3LReKo7vSXUPhHdh/4yFPBXSe5vPxVxtpjvpy82TaiWYRdW1bHWfgq4cIF5L0gyk+RQkmvGU9q8lvI8/vecqnoOOAFcMJbqTm+pr4EfbUsktyfZMs/4mehMfX0v1fcmeSDJR5J85zh2eMb9DMNaSPLXwEvmGfqVqrpjiXfz/VV1NMk3AQeTfKq9k6+pVap9Ik5X+/BGVVWShc4d/pb2vL8MuCfJQ1X1mdWuVfwZcFtVfTnJTzH4i+U1E67pa90nGLy+v5jkauBPgW1rvdMuQr+qfnAV7uNouz6e5E8Y/Mm85qG/CrVP7KcvTld7kqeTXFRVx9qf48cXuI+Tz/sTST4GvILB+vS4LeV5PDnnSJJ1wIuBz4+nvNNatPaqGq7zfQw+czkbnLU/7VJV/zzUvjPJ7ybZWFVr+iNyLu8sQZIXJfnGk23gCmDeT+TPQGfqT18cAHa29k7geX+1JNmQ5LzW3gi8CpjU/15YyvM4/JjeANxT7RO7CVu09lPWwV8PPDbG+kZxALiuncVzOXBiaNnwjJbkJSc/80lyGYM8XvuDhEl/wj3pC/AjDNYBvww8DdzV+r8ZuLO1X8bgjIcHgEcYLK2cFbW37auBf2BwhHym1H4BcDfwOPDXwPmtfxp4X2t/H/BQe94fAnZNuObnPY/Au4HXt/YLgD8EZoG/A1426ed5GbX/RnttPwB8FPj2Sdfc6roNOAb8e3ut7wLeBrytjYfBP2b6THuNLHgG3hlY+9uHnvNDwPeNoy5/hkGSOuLyjiR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHfkvfOJZD/IO16AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Initialize only classifier part\n",
    "initialize_weights(model.classifier)\n",
    "\n",
    "# After initialize weights\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))  # weight distribution for first conv weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adverse-disco",
   "metadata": {},
   "source": [
    "## Appendix (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-humanitarian",
   "metadata": {},
   "source": [
    "### SOTA (State Of The Art)  모델을 리서치 하는 방법\n",
    "- timm\n",
    "- paper with code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-accused",
   "metadata": {},
   "source": [
    "## timm (pyTorch IMage Models)\n",
    "\n",
    "PyTorch Image Models (timm) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.\n",
    "\n",
    "#### References\n",
    "https://github.com/rwightman/pytorch-image-models#introduction\n",
    "\n",
    "https://fastai.github.io/timmdocs/\n",
    "\n",
    "https://rwightman.github.io/pytorch-image-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "innovative-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n",
      "\u001b[K     |################################| 287 kB 133 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /home/covy/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages (from timm) (0.8.2)\n",
      "Requirement already satisfied: torch>=1.4 in /home/covy/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages (from timm) (1.7.1)\n",
      "Requirement already satisfied: dataclasses in /home/covy/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages (from torch>=1.4->timm) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/covy/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /home/covy/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages (from torch>=1.4->timm) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/covy/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages (from torchvision->timm) (8.1.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-diesel",
   "metadata": {},
   "source": [
    "#### Timm 을 사용하여 pretrained 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "iraqi-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): HardSwishMe()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "        (bn2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): HardSwishMe()\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): HardSwishMe()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=False)\n",
       "  (conv_head): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (act2): HardSwishMe()\n",
       "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "m = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-friend",
   "metadata": {},
   "source": [
    "#### Timm 에서 사용가능한 pretrained 모델 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reserved-jordan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b2a',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b3a',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_lite0',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0c',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet101d',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_100',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_resnet50_224_in21k',\n",
      " 'vit_base_resnet50_384',\n",
      " 'vit_deit_base_distilled_patch16_224',\n",
      " 'vit_deit_base_distilled_patch16_384',\n",
      " 'vit_deit_base_patch16_224',\n",
      " 'vit_deit_base_patch16_384',\n",
      " 'vit_deit_small_distilled_patch16_224',\n",
      " 'vit_deit_small_patch16_224',\n",
      " 'vit_deit_tiny_distilled_patch16_224',\n",
      " 'vit_deit_tiny_patch16_224',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-republican",
   "metadata": {},
   "source": [
    "#### 다음과 같은 방법을 통해서 원하는 모델을 찾는 것도 가능합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "average-compression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cspresnet50',\n",
      " 'cspresnet50d',\n",
      " 'cspresnet50w',\n",
      " 'cspresnext50',\n",
      " 'cspresnext50_iabn',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet200d',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'ecaresnext26t_32x4d',\n",
      " 'ecaresnext50t_32x4d',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'nf_ecaresnet26',\n",
      " 'nf_ecaresnet50',\n",
      " 'nf_ecaresnet101',\n",
      " 'nf_resnet26',\n",
      " 'nf_resnet50',\n",
      " 'nf_resnet101',\n",
      " 'nf_seresnet26',\n",
      " 'nf_seresnet50',\n",
      " 'nf_seresnet101',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200',\n",
      " 'resnet200d',\n",
      " 'resnetblur18',\n",
      " 'resnetblur50',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'resnext101_64x4d',\n",
      " 'seresnet18',\n",
      " 'seresnet34',\n",
      " 'seresnet50',\n",
      " 'seresnet50t',\n",
      " 'seresnet101',\n",
      " 'seresnet152',\n",
      " 'seresnet152d',\n",
      " 'seresnet200d',\n",
      " 'seresnet269d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26tn_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'seresnext101_32x4d',\n",
      " 'seresnext101_32x8d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnet50',\n",
      " 'skresnet50d',\n",
      " 'skresnext50_32x4d',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'vit_base_resnet26d_224',\n",
      " 'vit_base_resnet50_224_in21k',\n",
      " 'vit_base_resnet50_384',\n",
      " 'vit_base_resnet50d_224',\n",
      " 'vit_small_resnet26d_224',\n",
      " 'vit_small_resnet50d_s3_224',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models('*resne*t*')\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-rehabilitation",
   "metadata": {},
   "source": [
    "## Paper with code\n",
    " - https://paperswithcode.com/task/image-classification\n",
    " - 다양한 태스크와 데이터셋에 대한 다양한 모델들의 성능을 벤치마킹해주는 웹서비스입니다.\n",
    " - 해당 서비스를 통해 각 모델들의 성능 비교뿐 아니라 논문과 구현 코드로 forwarding 도 가능합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
